---
title: 词频统计
date: 2023-04-11 21:22:56
tags: python
categories: 词频统计
---
毕业季了，遇到别人毕设需要用到python，友情帮助了一下，记录一下。

大概目标是爬取上市公司年报，并进行关键词频率统计，爬取网站是巨潮资讯。
以下链接能获取到巨潮资讯A股公司的一些不要信息，如图所示，<!--more-->
[http://www.cninfo.com.cn/new/data/szse_stock.json](http://www.cninfo.com.cn/new/data/szse_stock.json)
![](/img/巨潮.png)

还是直接上代码吧
{% spoiler "点击显/隐内容" %}
```python
import os
import os ,xlrd
import requests,time,json
import pandas as pd
import xlrd,os
def req(stock,year,org_dict):
    # post请求地址（巨潮资讯网的那个查询框实质为该地址）
    url = "http://www.cninfo.com.cn/new/hisAnnouncement/query"
    # 表单数据，需要在浏览器开发者模式中查看具体格式
    data  = {
        "pageNum":"1",
        "pageSize":"30",
        "tabName":"fulltext",
        "stock":stock + "," + org_dict[stock] ,# 按照浏览器开发者模式中显示的参数格式构造参数
        "seDate":f"{str(int(year)+1)}-01-01~{str(int(year)+1)}-12-31",
        "column":"szse",
        "category":"category_ndbg_szsh",
        "isHLtitle": "true",
        "sortName":"time",
        "sortType": "desc"
        }
    # 请求头
    headers =  {"Content-Length": "201","Content-Type":"application/x-www-form-urlencoded"}
    # 发起请求
    req = requests.post(url,data=data,headers=headers)

    url_item = []
    list_item = json.loads(req.text)["announcements"]
    if not list_item:# 确保json.loads(req.text)["announcements"]非空，是可迭代对象
        return
    for item in list_item:# 遍历announcements列表中的数据，目的是排除英文报告和报告摘要，唯一确定年度报告或者更新版
        if "摘要"  in item["announcementTitle"]:
            continue
        if "取消"  in item["announcementTitle"]:
            continue
        if "英文"  in item["announcementTitle"]:
            continue
        if "修订" in item["announcementTitle"] or "更新" in item["announcementTitle"] or "更正" in item["announcementTitle"]:
            adjunctUrl = item["adjunctUrl"] # "finalpage/2019-04-30/1206161856.PDF" 中间部分便为年报发布日期，只需对字符切片即可
            pdfurl = "http://static.cninfo.com.cn/" + adjunctUrl
            year  = getYear(item["announcementTitle"])
            if(year):
                item = {}
                item["url"] = pdfurl
                item["year"] = year
                url_item.append(item)
            else:#年报标题上无年份，或含年份外的其他数字
                downloadError(pdfurl,stock)
            df = pd.DataFrame([pdfurl])
            df.to_csv('年报url.csv', mode='a', index=False, header=False)  
        else:
            adjunctUrl = item["adjunctUrl"] # "finalpage/2019-04-30/1206161856.PDF" 中间部分便为年报发布日期，只需对字符切片即可
            pdfurl = "http://static.cninfo.com.cn/" + adjunctUrl
            year  = getYear(item["announcementTitle"])
            if(year):
                item = {}
                item["url"] = pdfurl
                item["year"] = year
                url_item.append(item)
            else:
                downloadError(pdfurl,stock)
            df = pd.DataFrame([pdfurl])
            df.to_csv('年报url.csv', mode='a', index=False, header=False)
    download(url_item,stock)

def download(url_item,stock):# 下载年报
    s = requests.session()
    s.keep_alive = False
    for i in url_item:
        r = s.get(i['url'])
        if not os.path.exists("年度报告/年报/"+ stock +'/'):
            os.makedirs("年度报告/年报/"+ stock +'/' )
        f = open("年度报告/年报/"+ stock +'/'+stock+ "-" + i['year'] + "年度报告" + ".pdf", "wb")
        f.write(r.content)                       
        print(f"{stock}-{i['year']}年报下载完成！") # 打印进度

def downloadError(url,stock):# 存在公司年报不带年份下载到“存在问题年报文件夹”文件夹
    s = requests.session()
    s.keep_alive = False
    r = s.get(url)
    if not os.path.exists("存在问题年报/"+ stock +'/'):
        os.makedirs("存在问题年报/"+ stock +'/' )
    f = open("存在问题年报/"+ stock +'/'+stock+ "-" + "年度报告" + ".pdf", "wb")
    f.write(r.content)                       
    print(f"{stock}年报下载完成！") # 打印进度

def get_orgid():#获取A股公司代码对应的OrgId,用于构造表单数据
    org_dict = {}
    org_json = requests.get("http://www.cninfo.com.cn/new/data/szse_stock.json").json()["stockList"]

    for i in range(len(org_json)):
        org_dict[org_json[i]["code"]] = org_json[i]["orgId"]

    return org_dict

def getYear(tile:str):#获取年报标题上的年份，便于对年报进行重命名
    year = ''
    for i in tile:
        if i.isdigit():
            year += i
    if len(year) == 4:
        return year
    return False
def check(number):#检查xls文件格式，调整文件内容
    if type(number) == str:
        if len(number) == 6 and number.isdigit():
            return number
    if type(number) == float:
        tem = str(int(number))
        if len(tem) < 6:
            lenth = 6 - len(tem)
            for i in range(lenth):
                tem = "0" + tem
        return tem
    else:
        print("格式错误：",number)

def getNumber():#获取xls文件内的公司代码
    list_number = []
    with xlrd.open_workbook("出口上市公司.xls") as book:
        sheets = book.sheets()
        for sheet in sheets:
            rows = sheet.nrows
            for i in range(1, rows):
                list1 = sheet.row_values(rowx=i)
                number = check(list1[0])
                if number == None:
                    continue
                else:
                    list_number.append(number)
    return list_number
if __name__ == '__main__':    
    org_dict = get_orgid()
    list_number = getNumber()
    for number in list_number:# 一层按股票代码循环
        for year in ["2015","2016","2017","2018","2019","2020","2021"]:# 下载所需要的年份年报
            req(number ,year,org_dict)# 调用req函数
            time.sleep(0.5)# 适当休眠，避免爬虫过快

```
{% endspoiler %}
除了爬虫部分，剩余部分比较简单，也不再多解释

接下来需要把下载的pdf转txt，由于文件过多，使用多进程加速处理
{% spoiler "点击显/隐内容" %}
```python
from pdfminer.high_level import extract_text
import os ,psutil
import multiprocessing          
def pdf2txt(folder_name):#转换函数,多进程调用函数
    list_filename = os.listdir(folder_name)
    for filename in list_filename:
            if  filename.endswith(".PDF")  or filename.endswith(".pdf"):
                print(folder_name+filename+":转换中......")
                text = extract_text(folder_name+filename)
                with open(folder_name+filename[:-4]+".txt", "w", encoding="utf-8") as f:
                    f.write(text)
                print(folder_name+filename+":转换成功")
                os.remove(folder_name+filename)

def main():#使用多进程，提高转换速度
    
    list_folder_name = next(os.walk("出口上市公司年报/"))[1]
    pool = multiprocessing.Pool(processes = psutil.cpu_count()+1)
    for folder_name in list_folder_name:
        pool.apply_async(pdf2txt, ("出口上市公司年报/"+folder_name+'/',))
    pool.close()
    pool.join()

if __name__ == '__main__':
    main()
```
{% endspoiler %}

pdf转转完后进行词频统计，依然使用多进程加速处理。

{% spoiler "点击显/隐内容" %}
```python
# 导入依赖
import jieba,os,psutil,xlrd
import pandas as pd
import multiprocessing
# 定义关键词列表

key_word = []

with xlrd.open_workbook("关键词.xls") as book:
        sheets = book.sheets()
        for sheet in sheets:
            rows = sheet.nrows
        for i in range(rows):
            list1 = sheet.row_values(rowx=i)
            key_word.append((list1[0]))
def getKeyWordData(text_path,filer_name):
    
    # 读取文本
    key_word_data = {}
    path_filename = text_path + filer_name
    with  open(path_filename, "r", encoding='utf-8') as f:
        txt = f.read()
        # 使用精确模式对文本进行分词
        words = jieba.lcut(txt)
        # 通过键值对的形式存储词语及其出现的次数
        year = filer_name[:-8]
       
        year  = year[-4:]#获取年份
        filer_name = filer_name[:-13]#获取公司代码
       
        key_word_data['公司代码'] = filer_name+'年报'
        key_word_data['年份'] = year
        for wd in key_word:
            key_word_data[wd] = words.count(wd)#统计关键词出现次数
    return key_word_data   
def statistics(folder_name):
    list_filename = os.listdir("出口上市公司年报/"+folder_name)
    for filename in list_filename:
        if filename.endswith(".txt"):
            key_word_data = getKeyWordData("出口上市公司年报/"+folder_name+"/",filename)
            #os.remove("年度报告/"+folder_name+"/"+filename)
            print(filename+"分析完成")
            datas = []
            datas.append(key_word_data)
            df = pd.DataFrame(datas)
                    
            if not os.path.exists('所有词频数据.csv') :
                df.to_csv('所有词频数据.csv', mode='a', index=False,header=True)
            else:
                df.to_csv('所有词频数据.csv', mode='a', index=False, header=False)
            os.remove("出口上市公司年报/"+folder_name+"/"+filename)
        else:
            print(filename+"不是txt文件")

# 主函数
def main():
    list_folder_name = next(os.walk("出口上市公司年报/"))[1]
    pool = multiprocessing.Pool(processes = psutil.cpu_count()+1)#使用多进程，提高统计速度
    for folder_name in list_folder_name:
        pool.apply_async(statistics, (folder_name,))#一个进程处理一个文件夹
    pool.close()
    pool.join()
   
    
if __name__ == '__main__':
    main()


```
{% endspoiler %}

